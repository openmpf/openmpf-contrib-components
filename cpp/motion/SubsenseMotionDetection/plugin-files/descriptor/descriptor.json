{
  "componentName": "SubsenseMotionDetection",
  "componentVersion": "7.2",
  "middlewareVersion": "7.2",
  "sourceLanguage": "c++",
  "batchLibrary": "${MPF_HOME}/plugins/SubsenseMotionDetection/lib/libmpfSubsenseMotionDetection.so",
  "streamLibrary": "${MPF_HOME}/plugins/SubsenseMotionDetection/lib/libmpfSubsenseStreamingMotionDetection.so",
  "environmentVariables": [
    {
      "name": "LD_LIBRARY_PATH",
      "value": "${MPF_HOME}/plugins/SubsenseMotionDetection/lib:${LD_LIBRARY_PATH}"
    }
  ],
  "algorithm": {
    "name": "SUBSENSE",
    "description": "Detects motion in videos using a Self-Balanced SENsitivity SEgmenter (SuBSENSE).",
    "actionType": "DETECTION",
    "requiresCollection": {
      "states": []
    },
    "providesCollection": {
      "states": [
        "DETECTION",
        "DETECTION_MOTION",
        "DETECTION_MOTION_SUBSENSE"
      ],
      "properties": [
        {
          "name": "USE_MOTION_TRACKING",
          "description": "0: Do not use tracking algorithm (old method). 1: Use STRUCK tracking.",
          "type": "INT",
          "defaultValue": "0"
        },
        {
          "name": "USE_PREPROCESSOR",
          "description": "Enables the use of motion as a preprocessor. Only will return if motion is in frame. Overrides USE_MOTION_TRACKING.",
          "type": "INT",
          "defaultValue": "0"
        },
        {
          "name": "F_REL_LBSP_THRESHOLD",
          "description": "Relative threshold of the Local Binary Similarity Pattern (LBSP) algorithm.",
          "type": "FLOAT",
          "defaultValue": "0.333"
        },
        {
          "name": "N_MIN_DESC_DIST_THRESHOLD",
          "description": "Minimum descriptor distance threshold.",
          "type": "INT",
          "defaultValue": "3"
        },
        {
          "name": "N_MIN_COLOR_DIST_THRESHOLD",
          "description": "Minimum color distance threshold.",
          "type": "INT",
          "defaultValue": "30"
        },
        {
          "name": "N_BG_SAMPLES",
          "description": "Number of background samples.",
          "type": "INT",
          "defaultValue": "50"
        },
        {
          "name": "N_REQUIRED_BG_SAMPLES",
          "description": "Required number of background samples.",
          "type": "INT",
          "defaultValue": "2"
        },
        {
          "name": "N_SAMPLES_FOR_MOVING_AVGS",
          "description": "Number of samples for moving averages.",
          "type": "INT",
          "defaultValue": "25"
        },
        {
          "name": "MAXIMUM_FRAME_WIDTH",
          "description": "Maximum width of the frame passed to SuBSENSE. The frame will be downsampled until it is at or below the value. Smaller frames result in increased speed of SuBSENSE. The frame original aspect ratio is maintained.",
          "type": "INT",
          "defaultValue": "128"
        },
        {
          "name": "MAXIMUM_FRAME_HEIGHT",
          "description": "Maximum height of the frame passed to SuBSENSE. The frame will be downsampled until it is at or below the value. Smaller frames result in increased speed of SuBSENSE. The frame's original aspect ratio is maintained.",
          "type": "INT",
          "defaultValue": "128"
        },
        {
          "name": "MIN_RECT_WIDTH",
          "description": "Minimum width of detected motion in the original frame.",
          "type": "INT",
          "defaultValue": "16"
        },
        {
          "name": "MIN_RECT_HEIGHT",
          "description": "Minimum height of detected motion in the original frame.",
          "type": "INT",
          "defaultValue": "16"
        },
        {
          "name": "ERODE_ANCHOR_X",
          "description": "X position of the anchor within the element; -1 means that the anchor is at the element x center (definition from OpenCV).",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "ERODE_ANCHOR_Y",
          "description": "Y position of the anchor within the element; -1 means that the anchor is at the element y center (definition from OpenCV).",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "ERODE_ITERATIONS",
          "description": "The number of times erosion is applied.",
          "type": "INT",
          "defaultValue": "1"
        },
        {
          "name": "DILATE_ANCHOR_X",
          "description": "X position of the anchor within the element; -1 means that the anchor is at the element x center (definition from OpenCV).",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "DILATE_ANCHOR_Y",
          "description": "Y position of the anchor within the element; -1 means that the anchor is at the element y center (definition from OpenCV).",
          "type": "INT",
          "defaultValue": "-1"
        },
        {
          "name": "DILATE_ITERATIONS",
          "description": "The number of times dilation is applied.",
          "type": "INT",
          "defaultValue": "4"
        },
        {
          "name": "MEDIAN_BLUR_K_SIZE",
          "description": "Aperture linear size; it must be odd and greater than 1 (definition from OpenCV).",
          "type": "INT",
          "defaultValue": "3"
        },
        {
          "name": "GROUP_RECTANGLES_GROUP_THRESHOLD",
          "description": "Minimum possible number of rectangles minus 1. The threshold is used in a group of rectangles to retain it (definition from OpenCV).",
          "type": "INT",
          "defaultValue": "1"
        },
        {
          "name": "GROUP_RECTANGLES_EPS",
          "description": "Relative difference between sides of the rectangles to merge them into a group (definition from OpenCV).",
          "type": "DOUBLE",
          "defaultValue": "0.4"
        },
        {
          "name": "TRACKING_MAX_OBJECT_PERCENTAGE",
          "description": "Max size of track as percentage of frame.",
          "type": "DOUBLE",
          "defaultValue": "0.9"
        },
        {
          "name": "TRACKING_THRESHOLD",
          "description": "The threshold for STRUCK when determining if a track should stop.",
          "type": "DOUBLE",
          "defaultValue": "-1"
        },
        {
          "name": "DISTANCE_CONFIDENCE_WEIGHT_FACTOR",
          "description": "When calculating a detection's confidence, the weight given to the distance (in number of frames) between that detection and the frame(s) in the middle of the track. Its value must be greater than or equal to 0, and if it is not, it will be set to 0. The default value of 0 will result in this distance not being factored into the confidence calculation. If this and the SIZE_CONFIDENCE_WEIGHT_FACTOR are both equal to 0, then the confidence will be assigned a value of -1.",
          "type": "FLOAT",
          "defaultValue": "0"
        },
        {
          "name": "SIZE_CONFIDENCE_WEIGHT_FACTOR",
          "description": "When calculating a detection's confidence, the weight given to the size of that detection's bounding box. Its value must be greater than or equal to 0, and if it is not, it will be set to 0. The default value of 0 will result in the bounding box size not being factored into the confidence calculation. If this and the DISTANCE_CONFIDENCE_WEIGHT_FACTOR are both equal to 0, then the confidence will be assigned a value of -1.",
          "type": "FLOAT",
          "defaultValue": "0"
        },
        {
          "name": "VERBOSE",
          "description": "0: no debugging output 1: log all track results.",
          "type": "INT",
          "defaultValue": "0"
        }
      ]
    }
  },
  "actions": [
    {
      "name": "SUBSENSE MOTION DETECTION ACTION",
      "description": "Executes the SuBSENSE motion detection algorithm using the default parameters.",
      "algorithm": "SUBSENSE",
      "properties": []
    },
    {
      "name": "SUBSENSE MOTION DETECTION (WITH TRACKING) ACTION",
      "description": "Executes the SuBSENSE motion detection algorithm and groups the resulting detections into tracks.",
      "algorithm": "SUBSENSE",
      "properties": [
        {
          "name": "USE_MOTION_TRACKING",
          "value": 1
        }
      ]
    },
    {
      "name": "SUBSENSE MOTION DETECTION PREPROCESSOR ACTION",
      "description": "Executes an instance of the SuBSENSE motion detection algorithm tuned for pre-processing.",
      "algorithm": "SUBSENSE",
      "properties": [
        {
          "name": "TARGET_SEGMENT_LENGTH",
          "value": 500
        },
        {
          "name": "MIN_SEGMENT_LENGTH",
          "value": 25
        },
        {
          "name": "FRAME_INTERVAL",
          "value": 1
        },
        {
          "name": "MIN_GAP_BETWEEN_SEGMENTS",
          "value": 10
        },
        {
          "name": "USE_MOTION_TRACKING",
          "value": 0
        },
        {
          "name": "USE_PREPROCESSOR",
          "value": 1
        }
      ]
    },
    {
      "name": "SUBSENSE MOTION DETECTION (WITH AUTO-ORIENTATION) PREPROCESSOR ACTION",
      "description": "Executes an instance of the SuBSENSE motion detection algorithm tuned for pre-processing with rotation and/or flipping based on EXIF data or video metadata.",
      "algorithm": "SUBSENSE",
      "properties": [
        {
          "name": "TARGET_SEGMENT_LENGTH",
          "value": 500
        },
        {
          "name": "MIN_SEGMENT_LENGTH",
          "value": 25
        },
        {
          "name": "FRAME_INTERVAL",
          "value": 1
        },
        {
          "name": "MIN_GAP_BETWEEN_SEGMENTS",
          "value": 10
        },
        {
          "name": "USE_MOTION_TRACKING",
          "value": 0
        },
        {
          "name": "USE_PREPROCESSOR",
          "value": 1
        },
        {
          "name": "AUTO_ROTATE",
          "value": "true"
        },
        {
          "name": "AUTO_FLIP",
          "value": "true"
        }
      ]
    }
  ],
  "tasks": [
    {
      "name": "SUBSENSE MOTION DETECTION TASK",
      "description": "Performs SubSENSE motion detection.",
      "actions": [
        "SUBSENSE MOTION DETECTION ACTION"
      ]
    },
    {
      "name": "SUBSENSE MOTION DETECTION PREPROCESSOR TASK",
      "description": "Performs SubSENSE motion detection as a preprocessor.",
      "actions": [
        "SUBSENSE MOTION DETECTION PREPROCESSOR ACTION"
      ]
    },
    {
      "name": "SUBSENSE MOTION DETECTION (WITH AUTO-ORIENTATION) PREPROCESSOR TASK",
      "description": "Performs SubSENSE motion detection as a preprocessor with rotation and/or flipping based on EXIF data with rotation and/or flipping based on EXIF data or video metadata.",
      "actions": [
        "SUBSENSE MOTION DETECTION (WITH AUTO-ORIENTATION) PREPROCESSOR ACTION"
      ]
    },
    {
      "name": "SUBSENSE MOTION DETECTION (WITH TRACKING) TASK",
      "description": "Performs SubSENSE motion detection and tracking.",
      "actions": [
        "SUBSENSE MOTION DETECTION (WITH TRACKING) ACTION"
      ]
    }
  ],
  "pipelines": [
    {
      "name": "SUBSENSE MOTION DETECTION (WITH TRACKING) PIPELINE",
      "description": "Performs SubSENSE MOTION detection.",
      "tasks": [
        "SUBSENSE MOTION DETECTION (WITH TRACKING) TASK"
      ]
    },
    {
      "name": "SUBSENSE MOTION DETECTION (WITH TRACKING AND MARKUP) PIPELINE",
      "description": "Performs SubSENSE MOTION detection with markup.",
      "tasks": [
        "SUBSENSE MOTION DETECTION (WITH TRACKING) TASK",
        "OCV GENERIC MARKUP TASK"
      ]
    }
  ]
}

